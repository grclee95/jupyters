{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eb4c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2623cb31",
   "metadata": {},
   "source": [
    "### csv 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ad4e396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   code        name  price\n",
      "0     1       apple   3000\n",
      "1     2  watermelon  20000\n",
      "2     3        kiwi   2500\n"
     ]
    }
   ],
   "source": [
    "items = {\n",
    "    'code':[1, 2, 3],\n",
    "    'name':['apple', 'watermelon', 'kiwi'],\n",
    "    'price':[3000, 20000, 2500]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(items)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b00389",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/m1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b214ab02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('./data/pddata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7c7e1f",
   "metadata": {},
   "source": [
    "# 엑셀 파일 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4ecbd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            이름   1과목   2과목   3과목\n",
      "번호                                              \n",
      "1                          이효준  40.0   NaN  45.0\n",
      "2                          김성희  42.0  55.0  50.0\n",
      "3                          이연숙   NaN  60.0  55.0\n",
      "4                          노화현  50.0  70.0  60.0\n",
      "5                          최희순  55.0  75.0   NaN\n",
      "6                          정원주  60.0  80.0  70.0\n"
     ]
    }
   ],
   "source": [
    "#첫번째 열을 인덱스로 활용하도록 읽기\n",
    "df = pd.read_excel('./data/excel.xlsx', index_col = 0, sheet_name='Sheet1')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8106c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bq/22f7j5dn6x5dcpn8t77q8t4h0000gn/T/ipykernel_61044/160634885.py:3: FutureWarning: save is not part of the public API, usage can give unexpected results and will be removed in a future version\n",
      "  writer.save()\n"
     ]
    }
   ],
   "source": [
    "writer = pd.ExcelWriter('./data/excelwriter.xlsx')\n",
    "df.to_excel(writer)\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11b29966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__abstractmethods__', '__annotations__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__fspath__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_abc_impl', '_book', '_convert_to_alignment', '_convert_to_border', '_convert_to_color', '_convert_to_fill', '_convert_to_font', '_convert_to_number_format', '_convert_to_protection', '_convert_to_side', '_convert_to_stop', '_convert_to_style_kwargs', '_cur_sheet', '_date_format', '_datetime_format', '_deprecate', '_deprecate_set_book', '_docstring_components', '_engine', '_get_sheet_name', '_handles', '_if_sheet_exists', '_mode', '_path', '_save', '_supported_extensions', '_value_with_fmt', '_write_cells', 'book', 'check_extension', 'close', 'cur_sheet', 'date_format', 'datetime_format', 'engine', 'handles', 'if_sheet_exists', 'path', 'save', 'sheets', 'supported_extensions', 'write_cells']\n"
     ]
    }
   ],
   "source": [
    "print(dir(writer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8d2917",
   "metadata": {},
   "source": [
    "# HTML의 테이블 읽기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cbc37ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[         연도 디비 (Deevey, 1960) 맥에브디와 존즈 (McEvedy and Jones, 1978)  \\\n",
      "         연도 디비 (Deevey, 1960) 맥에브디와 존즈 (McEvedy and Jones, 1978)   \n",
      "0      B.C.                 -                                  -   \n",
      "1   1000000             0.125                                  -   \n",
      "2    300000                 1                                  -   \n",
      "3    250000              3.34                                  -   \n",
      "4    100000                 -                                  5   \n",
      "5      8000              5.32                                  -   \n",
      "6      5000                 -                                  5   \n",
      "7      4000              86.5                                  7   \n",
      "8      3000                 -                                 14   \n",
      "9      2000                 -                                 27   \n",
      "10     1000                 -                                 50   \n",
      "11      500                 -                                100   \n",
      "12      400                 -                                  -   \n",
      "13      200                 -                                150   \n",
      "14     A.D.                 -                                  -   \n",
      "15        1               133                                170   \n",
      "16      200                 -                                190   \n",
      "17      400                 -                                  -   \n",
      "18      500                 -                                190   \n",
      "19      600                 -                                200   \n",
      "20      700                 -                                210   \n",
      "21      800                 -                                220   \n",
      "22      900                 -                                240   \n",
      "23     1000             - 390                                NaN   \n",
      "\n",
      "   듀란 (Durand, 1977)      클라크 (Clark, 1977) 비라벤 (Biraben, 1979)  \\\n",
      "                  저위   고위 클라크 (Clark, 1977) 비라벤 (Biraben, 1979)   \n",
      "0                  -    -                 -                   -   \n",
      "1                  -    -                 -                   -   \n",
      "2                  -    -                 -                   -   \n",
      "3                  -    -                 -                   -   \n",
      "4                  -    -                 -                   -   \n",
      "5                  -    -                 -                   -   \n",
      "6                  -    -                 -                   -   \n",
      "7                  -    -                 -                   -   \n",
      "8                  -    -                 -                   -   \n",
      "9                  -    -                 -                   -   \n",
      "10                 -    -                 -                   -   \n",
      "11                 -    -                 -                   -   \n",
      "12                 -    -                 -                 153   \n",
      "13                 -    -                 -                 225   \n",
      "14                 -    -                 -                   -   \n",
      "15               270  330               256                 252   \n",
      "16                 -    -                 -                 257   \n",
      "17                 -    -                 -                 153   \n",
      "18                 -    -                 -                 207   \n",
      "19                 -    -               237                 208   \n",
      "20                 -    -                 -                 206   \n",
      "21                 -    -               261                 224   \n",
      "22                 -    -                 -                 222   \n",
      "23               NaN  NaN               NaN                 NaN   \n",
      "\n",
      "   블락스터 (Blaxter, 1986) 크레머 (Kremer, 1993)  \n",
      "   블락스터 (Blaxter, 1986) 크레머 (Kremer, 1993)  \n",
      "0                     -                  -  \n",
      "1                     -              0.125  \n",
      "2                     -                  1  \n",
      "3                     -               3.34  \n",
      "4                     -                  4  \n",
      "5                     -                  -  \n",
      "6                    40                  5  \n",
      "7                     -                 15  \n",
      "8                     -                 14  \n",
      "9                    70                 27  \n",
      "10                  100                 50  \n",
      "11                    -                100  \n",
      "12                  162                  -  \n",
      "13                  231                150  \n",
      "14                    -                  -  \n",
      "15                  255                170  \n",
      "16                  256                190  \n",
      "17                  162                  -  \n",
      "18                    -                  -  \n",
      "19                  206                200  \n",
      "20                  207                  -  \n",
      "21                  100                220  \n",
      "22                  226                  -  \n",
      "23                  NaN                NaN  ,           시기      세계 인구                      비고\n",
      "0   BC 4000년    1,500만명                    농경문화\n",
      "1   BC 2000년    5,000만명                   4대 문명\n",
      "2   BC 1000년        1억명                    철기문명\n",
      "3    BC 500년  1억 4000만명             그리스,춘추 전국시대\n",
      "4        기원년        2억명  로마 약 7,000만명,한나라 약 1억명\n",
      "5   AD 1000년        3억명            봉건 중세시대, 송나라\n",
      "6   AD 1392년        5억명          열병기 보급, 신대륙 발견\n",
      "7   AD 1700년       10억명            산업혁명, 식민지 팽창\n",
      "8   AD 1900년       20억명                 2차 산업혁명\n",
      "9   AD 1959년       30억명                     NaN\n",
      "10  AD 1974년       40억명                     NaN\n",
      "11  AD 1987년       50억명                     NaN\n",
      "12  AD 1999년       60억명                     NaN\n",
      "13  AD 2011년       70억명                     NaN\n",
      "14  AD 2022년    80억명[5]                     NaN,        연도     기원년   1000년      1500년      1600년      1700년      1820년  \\\n",
      "0      미국     NaN     NaN        NaN        NaN        NaN       980만   \n",
      "1      일본    300만    800만     1,800만     2,200만     2,800만     3,300만   \n",
      "2      중국  5,900만  5,900만    1억 300만  1억 6,000만  1억 3,800만  3억 8,000만   \n",
      "3      인도  7,500만  7,500만  1억 1,000만  1억 3,500만  1억 6,500만    2억 900만   \n",
      "4      영국     NaN     NaN       380만       560만        NaN     1,040만   \n",
      "5     프랑스     NaN     NaN     1,600만     1,800만     2,100만     3,300만   \n",
      "6      독일     NaN     NaN     1,600만     2,000만     1,500만     2,700만   \n",
      "7     러시아     NaN     NaN        NaN     1,400만     1,400만     4,000만   \n",
      "8      한국    160만    390만       800만       900만     1,200만     1,400만   \n",
      "9   인도네시아    280만    520만     1,070만     1,170만     1,310만     1,610만   \n",
      "10     세계    1.9억    3.1억       2.8억       6.0억       6.8억       8.1억   \n",
      "\n",
      "        1900년      1940년 Unnamed: 9 Unnamed: 10 Unnamed: 11  \n",
      "0      7,500만  1억 5,000만        NaN         NaN         NaN  \n",
      "1      4,300만     8,000만        NaN         NaN         NaN  \n",
      "2          4억  5억 8,000만        NaN         NaN         NaN  \n",
      "3   3억 3,000만        NaN        NaN         NaN         NaN  \n",
      "4      3,300만     3,800만        NaN         NaN         NaN  \n",
      "5      3,800만     5,000만        NaN         NaN         NaN  \n",
      "6      5,600만     6,500만        NaN         NaN         NaN  \n",
      "7      7,100만  1억 3,000만        NaN         NaN         NaN  \n",
      "8      1,700만     2,900만        NaN         NaN         NaN  \n",
      "9         NaN        NaN        NaN         NaN         NaN  \n",
      "10      10.0억      11.6억      13.1억         17억         24억  ,       연도           인구\n",
      "0   2023   8020890338\n",
      "1   2024   8098605255\n",
      "2   2025   8114437453\n",
      "3   2026   8359276651\n",
      "4   2027   8393078318\n",
      "..   ...          ...\n",
      "76  2099  10872284134\n",
      "77  2100  10875393719\n",
      "78  2101  10877000004\n",
      "79  2102  10899572951\n",
      "80  2103  11000000951\n",
      "\n",
      "[81 rows x 2 columns],                 0            1            2            3             4  \\\n",
      "0           지역/연도         1950         2020         2050          2080   \n",
      "1            아프리카   2억 2779만 명  13억 4059만 명  22억 8385만 명   36억 8057만 명   \n",
      "2             아시아   14억 490만 명  46억 4105만 명  52억 9026만 명   50억 6851만 명   \n",
      "3              유럽   5억 4932만 명   7억 4763만 명   7억 1048만 명    6억 4958만 명   \n",
      "4  라틴 아메리카 및 카리브해   1억 6882만 명   6억 5396만 명   7억 6243만 명    7억 3862만 명   \n",
      "5           북아메리카   1억 7260만 명   3억 6887만 명   4억 2520만 명    4억 6763만 명   \n",
      "6           오세아니아      1297만 명      4267만 명      5737만 명       6897만 명   \n",
      "7            전 세계  25억 3643만 명  77억 9479만 명  97억 3503만 명  106억 7390만 명   \n",
      "\n",
      "              5  \n",
      "0          2100  \n",
      "1   42억 8012만 명  \n",
      "2   47억 1990만 명  \n",
      "3    6억 2956만 명  \n",
      "4    6억 7999만 명  \n",
      "5    4억 9088만 명  \n",
      "6       7491만 명  \n",
      "7  108억 7539만 명  ,                지역 2020–25 2045–50 2095–2100\n",
      "0            아프리카    2.37    1.74      0.61\n",
      "1             아시아    0.77    0.14     −0.39\n",
      "2              유럽   −0.05   −0.26     −0.14\n",
      "3  라틴 아메리카 및 카리브해    0.84    0.21     −0.46\n",
      "4           북아메리카    0.59    0.38      0.25\n",
      "5           오세아니아    1.21    0.80      0.37\n",
      "6            전 세계    0.98    0.53      0.04,       0                   1                   2                       3  \\\n",
      "0   NaN                1990                2019                    2050   \n",
      "1    1위    중국 (11억 7770만 명)    중국 (14억 3400만 명)        인도 (16억 3900만 명)   \n",
      "2    2위     인도 (8억 7300만 명)    인도 (13억 6600만 명)         중국 (14억 200만 명)   \n",
      "3    3위     미국 (2억 5200만 명)     미국 (3억 2900만 명)       나이지리아 (4억 100만 명)   \n",
      "4    4위  인도네시아 (1억 8100만 명)  인도네시아 (2억 7100만 명)         미국 (3억 7900만 명)   \n",
      "5    5위    브라질 (1억 4900만 명)   파키스탄 (2억 1700만 명)       파키스탄 (3억 3800만 명)   \n",
      "6    6위    러시아 (1억 4800만 명)    브라질 (2억 1100만 명)      인도네시아 (3억 3100만 명)   \n",
      "7    7위     일본 (1억 2500만 명)   나이지리아 (2억 100만 명)        브라질 (2억 2900만 명)   \n",
      "8    8위    파키스탄 (1억 800만 명)  방글라데시 (1억 6300만 명)       에티오피아 (2억 500만 명)   \n",
      "9    9위   방글라데시 (1억 300만 명)    러시아 (1억 4600만 명)  콩고 민주 공화국 (1억 9400만 명)   \n",
      "10  10위     나이지리아 (9500만 명)    멕시코 (1억 2800만 명)      방글라데시 (1억 9300만 명)   \n",
      "\n",
      "                         4  \n",
      "0                     2100  \n",
      "1         인도 (14억 5000만 명)  \n",
      "2         중국 (10억 6500만 명)  \n",
      "3       나이지리아 (7억 3300만 명)  \n",
      "4          미국 (4억 3400만 명)  \n",
      "5         파키스탄 (4억 300만 명)  \n",
      "6   콩고 민주 공화국 (3억 6200만 명)  \n",
      "7       인도네시아 (3억 2100만 명)  \n",
      "8       에티오피아 (2억 9400만 명)  \n",
      "9        탄자니아 (2억 8600만 명)  \n",
      "10        이집트 (2억 2500만 명)  ,            0   1\n",
      "0  전거 통제: 국가  독일]\n"
     ]
    }
   ],
   "source": [
    "li = pd.read_html(\"https://ko.wikipedia.org/wiki/%EC%84%B8%EA%B3%84_%EC%9D%B8%EA%B5%AC\")\n",
    "print(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6665cc",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 파이썬 기본 라이브러리 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66e878ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2628843905.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[1], line 9\u001b[0;36m\u001b[0m\n\u001b[0;31m    + keyword +\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "from urllib.parse import quote\n",
    "\n",
    "#인코딩\n",
    "keyword = quote(\"사이버가수아담\")\n",
    "\n",
    "#데이터 읽어오기\n",
    "response = urllib.request.urlopen(\"https://search.hani.co.kr/search?searchword=%EC%82%AC%EC%9D%B4%EB%B2%84%EA%B0%80%EC%88%98%EC%95%84%EB%8B%B4&sort=desc&startdate=1988.01.01&enddate=2023.08.09\")\n",
    "+ keyword + \n",
    "\n",
    "#읽은 정보를 저장\n",
    "data = response.read()\n",
    "#print(data) #바로 출력했더니 인코딩 문제가 발생\n",
    "\n",
    "#데이터의 인코딩을 확인해서 인코딩 설정해서 읽기\n",
    "encoding = response.info().get_content_charset()\n",
    "html = data.decode(encoding)\n",
    "print(html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398148a0",
   "metadata": {},
   "source": [
    "# Request 모듈 - 파이썬의 기본 모듈이 아님"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb19991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.29.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-64d2f063-79bc6fca741594f352aa6fb3\"\n",
      "  }, \n",
      "  \"origin\": \"1.220.201.108\", \n",
      "  \"url\": \"http://httpbin.org/get\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "#get 방식 요청\n",
    "response = requests.get('http://httpbin.org/get')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ede51c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"args\": {}, \n",
      "  \"data\": \"\", \n",
      "  \"files\": {}, \n",
      "  \"form\": {\n",
      "    \"alias\": \"adam\", \n",
      "    \"id\": \"itstudy\", \n",
      "    \"name\": \"\\ubc15\\ubb38\\uc11d\"\n",
      "  }, \n",
      "  \"headers\": {\n",
      "    \"Accept\": \"*/*\", \n",
      "    \"Accept-Encoding\": \"gzip, deflate, br\", \n",
      "    \"Content-Length\": \"54\", \n",
      "    \"Content-Type\": \"application/x-www-form-urlencoded\", \n",
      "    \"Host\": \"httpbin.org\", \n",
      "    \"User-Agent\": \"python-requests/2.29.0\", \n",
      "    \"X-Amzn-Trace-Id\": \"Root=1-64d2f0c5-328ecff52632420e2a536a62\"\n",
      "  }, \n",
      "  \"json\": null, \n",
      "  \"origin\": \"1.220.201.108\", \n",
      "  \"url\": \"http://httpbin.org/post\"\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#post 방식\n",
    "#전송할 파라미터 만들기\n",
    "dic = {\"id\":\"itstudy\", \"name\":\"박문석\", \"alias\":\"adam\"}\n",
    "#요청을 하고 응답 받기\n",
    "response = requests.post('http://httpbin.org/post', data=dic)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48135094",
   "metadata": {},
   "source": [
    "# html 파싱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff97aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, bs4\n",
    "\n",
    "try:\n",
    "    #url이 잘못되었거나 네트워크 연결이 안되면 예외가 발생\n",
    "    response = requests.get('http://finance.daum.net')\n",
    "    \n",
    "    #파싱 가능한지 확인 - 파싱이 불가능하면 예외가 발생\n",
    "    bs = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"예외 발생:\", e)\n",
    "\n",
    "else:\n",
    "    print(bs.body.strong.get_text())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f9e15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#네이버 팟캐스트에서 원하는 데이터 가져오기\n",
    "try:\n",
    "    response = requests.get(\"https://tv.naver.com/r/category/drama\")\n",
    "    html = response.text\n",
    "    \n",
    "    #html 파싱 객체 생성\n",
    "    bs = bs4.BeautifulSoup(html, 'html.parser')\n",
    "    #print(bs)\n",
    "    #선택자에 해당하는 부분만 가져오기\n",
    "    tags = bs.select(\"a > strong > span\")\n",
    "    \n",
    "    for tag in tags:\n",
    "        print(tag.getText())\n",
    "    \n",
    "except Exception as e:\n",
    "    print(\"예외 발생:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90c5678e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'send_keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 18\u001b[0m\n\u001b[1;32m     14\u001b[0m num_of_pagedowns \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m num_of_pagedowns:\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#body 태그에 PAGE_DOWN을 전송해서 하단으로 드래그\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     driver\u001b[38;5;241m.\u001b[39mfind_element(By\u001b[38;5;241m.\u001b[39mTAG_NAME, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msend_keys(Keys\u001b[38;5;241m.\u001b[39mPAGE_DOWN)\n\u001b[1;32m     19\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     20\u001b[0m     num_of_pagedowns \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'send_keys'"
     ]
    }
   ],
   "source": [
    "#크롬 브라우저 실행\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import time\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import bs4\n",
    "\n",
    "os.environ['webdriver.chrome.driver'] = 'Users\\m1\\Downloads\\chromedriver-mac-arm64'\n",
    "driver = webdriver.Chrome()\n",
    "driver.get(\"https://www.youtube.com/results?search_query=%EA%B9%80%EC%97%B0%EA%B2%BD\")\n",
    "\n",
    "#스크롤 할 개수\n",
    "num_of_pagedowns = 10\n",
    "\n",
    "while num_of_pagedowns:\n",
    "    #body 태그에 PAGE_DOWN을 전송해서 하단으로 드래그\n",
    "    driver.find_element(By.TAG_NAME, 'body').send_keys(Keys.PAGE_DOWN)\n",
    "    time.sleep(3)\n",
    "    num_of_pagedowns -= 1\n",
    "\n",
    "#10번 스크롤 한 결과를 읽어오기\n",
    "html = bs4.BeautifulSoup(driver.page_source, 'html.parser')\n",
    "print(html)\n",
    "\n",
    "while(True):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "96d597dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as et #XML 파싱을 위한 import\n",
    "import urllib.request #웹에서 문자열 다운로드 받기 위해서 import\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8f3e2a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 다운로드\n",
    "url = 'http://www.hani.co.kr/rss/sports'\n",
    "request = urllib.request.Request(url)\n",
    "response = urllib.request.urlopen(request)\n",
    "#print(response.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "90da7423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Element 'rss' at 0x108b1d260>\n"
     ]
    }
   ],
   "source": [
    "#루트를 찾기\n",
    "tree = et.parse(response)\n",
    "xroot = tree.getroot()\n",
    "print(xroot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "df23461c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element 'channel' at 0x1192dcef0>]\n"
     ]
    }
   ],
   "source": [
    "#찾고자 하는 태그의 내용을 가져오기\n",
    "channel = xroot.findall('channel')\n",
    "print(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "011a02bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<Element 'item' at 0x1192df290>, <Element 'item' at 0x1192def20>, <Element 'item' at 0x1192dec00>, <Element 'item' at 0x1192de980>, <Element 'item' at 0x1192de700>, <Element 'item' at 0x1192de0c0>, <Element 'item' at 0x1192dde90>, <Element 'item' at 0x1192ddee0>, <Element 'item' at 0x1192ddcb0>, <Element 'item' at 0x1192dd990>, <Element 'item' at 0x1192dd760>, <Element 'item' at 0x1192dd4e0>, <Element 'item' at 0x1192dc9f0>, <Element 'item' at 0x1192e6ac0>, <Element 'item' at 0x1192e6110>, <Element 'item' at 0x1192e5ee0>, <Element 'item' at 0x1192e5e90>, <Element 'item' at 0x1192e5c10>, <Element 'item' at 0x1192e5760>, <Element 'item' at 0x1192e54e0>, <Element 'item' at 0x1192e4fe0>, <Element 'item' at 0x1192e4d60>, <Element 'item' at 0x1192e4ef0>, <Element 'item' at 0x1192e48b0>, <Element 'item' at 0x1192e4540>, <Element 'item' at 0x1192e4220>, <Element 'item' at 0x1192e41d0>, <Element 'item' at 0x1192f36a0>, <Element 'item' at 0x1192f3920>, <Element 'item' at 0x1192f3b50>]\n"
     ]
    }
   ],
   "source": [
    "#channel의 0번 데이터에서 item 태그의 내용 찾아오기\n",
    "items = channel[0].findall('item')\n",
    "print(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f5f5b172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "홈런 1위 노시환, 한화 선수 5년 만의 월간 MVP http://www.hani.co.kr/arti/sports/baseball/1103633.html\n",
      "장현석, 다저스와 90만달러 입단 계약…“명문 구단 입단 영광” http://www.hani.co.kr/arti/sports/baseball/1103621.html\n",
      "리빌딩 나선 PSG, 메시·음바페 이어 네이마르도 ‘헤어질 결심’ http://www.hani.co.kr/arti/sports/soccer/1103468.html\n",
      "강습 타구 맞은 류현진 “무릎에 멍들었지만 괜찮다” http://www.hani.co.kr/arti/sports/baseball/1103465.html\n",
      "김하성 15경기 연속 멀티 출루…이치로와 타이 기록 http://www.hani.co.kr/arti/sports/baseball/1103449.html\n",
      "클리블랜드전 무피안타 류현진, 강습 타구에 무릎 맞고 교체 http://www.hani.co.kr/arti/sports/baseball/1103415.html\n",
      "수원FC 공격수 라스 음주운전 적발…“징계·후속 조치할 것” http://www.hani.co.kr/arti/sports/soccer/1103324.html\n",
      "류현진, 시즌 첫 승 노린다…8일 클리블랜드전 등판 http://www.hani.co.kr/arti/sports/baseball/1103293.html\n",
      "조규성, 덴마크 데뷔 뒤 3경기 연속골…팀 열세 속 빛난 만회포 http://www.hani.co.kr/arti/sports/soccer/1103255.html\n",
      "‘부상 투혼’ 김효주, LPGA 스코틀랜드 여자오픈 준우승 http://www.hani.co.kr/arti/sports/golf/1103254.html\n",
      "‘최강’ 미국 여자축구, 16강 승부차기 끝에 스웨덴에 패배 http://www.hani.co.kr/arti/sports/soccer/1103235.html\n",
      "‘제주의 딸’ 임진희, 삼다수 마스터스 우승 http://www.hani.co.kr/arti/sports/golf/1103202.html\n",
      "궤도 오른 프로당구…‘심야 편성’에 팬 반발 커져 http://www.hani.co.kr/arti/sports/sports_general/1103201.html\n",
      "결승전서 21점 뽑아낸 강소휘…MVP도 3번째 수상 http://www.hani.co.kr/arti/sports//1103188.html\n",
      "공격 돌파구 날린 천가람 “더 강한 선수 되겠다” http://www.hani.co.kr/arti/sports/soccer/1103145.html\n",
      "GS칼텍스, 기업은행에 3-1 설욕…6번째 KOVO컵 정상 http://www.hani.co.kr/arti/sports//1103131.html\n",
      "승패 가른 김가영 샷…“초클루와 연습한 공 나와 짜릿했어요” http://www.hani.co.kr/arti/sports/sports_general/1103099.html\n",
      "KBO리그 500만 관중 돌파…평균 관중 1만1033명 http://www.hani.co.kr/arti/sports/baseball/1103095.html\n",
      "기업은행, 3-1로 인삼공사 꺾고 결승행…GS칼텍스와 맞대결 http://www.hani.co.kr/arti/sports//1103093.html\n",
      "김연경·박인비 등 6명, IOC 선수위원 ‘국내 후보’ 등록 http://www.hani.co.kr/arti/sports/sports_general/1103092.html\n",
      "GS칼텍스, 3-1로 현대건설 꺾고 결승행…KOVO컵 2연패 도전 http://www.hani.co.kr/arti/sports//1103079.html\n",
      "기적도 치욕도 반복된다…여자월드컵 강타한 ‘언더도그 돌풍’ http://www.hani.co.kr/arti/sports/soccer/1103055.html\n",
      "오타니, 시즌 40호 홈런…오른손 경련으로 투구는 4이닝만 http://www.hani.co.kr/arti/sports/baseball/1103047.html\n",
      "KBO리그 500만 관중 오늘 돌파…10개 구단 관중수입 762억 http://www.hani.co.kr/arti/sports/baseball/1103042.html\n",
      "에스와이 여성 삼총사 “산체스 정말 ‘진국’…팀 분위기 최고” http://www.hani.co.kr/arti/sports/sports_general/1103014.html\n",
      "‘오기상’이 그리는 안산의 새로운 배구…웃으면서 해도 “OK” http://www.hani.co.kr/arti/sports//1102999.html\n",
      "여자축구 조소현, 한국 첫·마지막 골 쐈다…독일 탈락시켜 http://www.hani.co.kr/arti/sports/soccer/1102962.html\n",
      "네이마르 2골1도움·이강인 24분…PSG, 부산을 파리로 만들다 http://www.hani.co.kr/arti/sports/soccer/1102946.html\n",
      "조기성, 세계장애인선수권 개인혼영 150ｍ 은메달 http://www.hani.co.kr/arti/sports/sports_general/1102897.html\n",
      "여자축구 1년 수입 ‘톱’ 15명 합쳐도…호날두 3분의 1도 안 돼 http://www.hani.co.kr/arti/sports/soccer/1102887.html\n",
      "                                    title  \\\n",
      "0           홈런 1위 노시환, 한화 선수 5년 만의 월간 MVP   \n",
      "1     장현석, 다저스와 90만달러 입단 계약…“명문 구단 입단 영광”   \n",
      "2    리빌딩 나선 PSG, 메시·음바페 이어 네이마르도 ‘헤어질 결심’   \n",
      "3            강습 타구 맞은 류현진 “무릎에 멍들었지만 괜찮다”   \n",
      "4            김하성 15경기 연속 멀티 출루…이치로와 타이 기록   \n",
      "5        클리블랜드전 무피안타 류현진, 강습 타구에 무릎 맞고 교체   \n",
      "6       수원FC 공격수 라스 음주운전 적발…“징계·후속 조치할 것”   \n",
      "7            류현진, 시즌 첫 승 노린다…8일 클리블랜드전 등판   \n",
      "8     조규성, 덴마크 데뷔 뒤 3경기 연속골…팀 열세 속 빛난 만회포   \n",
      "9        ‘부상 투혼’ 김효주, LPGA 스코틀랜드 여자오픈 준우승   \n",
      "10      ‘최강’ 미국 여자축구, 16강 승부차기 끝에 스웨덴에 패배   \n",
      "11               ‘제주의 딸’ 임진희, 삼다수 마스터스 우승   \n",
      "12            궤도 오른 프로당구…‘심야 편성’에 팬 반발 커져   \n",
      "13           결승전서 21점 뽑아낸 강소휘…MVP도 3번째 수상   \n",
      "14            공격 돌파구 날린 천가람 “더 강한 선수 되겠다”   \n",
      "15       GS칼텍스, 기업은행에 3-1 설욕…6번째 KOVO컵 정상   \n",
      "16      승패 가른 김가영 샷…“초클루와 연습한 공 나와 짜릿했어요”   \n",
      "17         KBO리그 500만 관중 돌파…평균 관중 1만1033명   \n",
      "18      기업은행, 3-1로 인삼공사 꺾고 결승행…GS칼텍스와 맞대결   \n",
      "19      김연경·박인비 등 6명, IOC 선수위원 ‘국내 후보’ 등록   \n",
      "20   GS칼텍스, 3-1로 현대건설 꺾고 결승행…KOVO컵 2연패 도전   \n",
      "21       기적도 치욕도 반복된다…여자월드컵 강타한 ‘언더도그 돌풍’   \n",
      "22       오타니, 시즌 40호 홈런…오른손 경련으로 투구는 4이닝만   \n",
      "23   KBO리그 500만 관중 오늘 돌파…10개 구단 관중수입 762억   \n",
      "24     에스와이 여성 삼총사 “산체스 정말 ‘진국’…팀 분위기 최고”   \n",
      "25     ‘오기상’이 그리는 안산의 새로운 배구…웃으면서 해도 “OK”   \n",
      "26        여자축구 조소현, 한국 첫·마지막 골 쐈다…독일 탈락시켜   \n",
      "27    네이마르 2골1도움·이강인 24분…PSG, 부산을 파리로 만들다   \n",
      "28            조기성, 세계장애인선수권 개인혼영 150ｍ 은메달   \n",
      "29  여자축구 1년 수입 ‘톱’ 15명 합쳐도…호날두 3분의 1도 안 돼   \n",
      "\n",
      "                                                 link  \n",
      "0   http://www.hani.co.kr/arti/sports/baseball/110...  \n",
      "1   http://www.hani.co.kr/arti/sports/baseball/110...  \n",
      "2   http://www.hani.co.kr/arti/sports/soccer/11034...  \n",
      "3   http://www.hani.co.kr/arti/sports/baseball/110...  \n",
      "4   http://www.hani.co.kr/arti/sports/baseball/110...  \n",
      "5   http://www.hani.co.kr/arti/sports/baseball/110...  \n",
      "6   http://www.hani.co.kr/arti/sports/soccer/11033...  \n",
      "7   http://www.hani.co.kr/arti/sports/baseball/110...  \n",
      "8   http://www.hani.co.kr/arti/sports/soccer/11032...  \n",
      "9   http://www.hani.co.kr/arti/sports/golf/1103254...  \n",
      "10  http://www.hani.co.kr/arti/sports/soccer/11032...  \n",
      "11  http://www.hani.co.kr/arti/sports/golf/1103202...  \n",
      "12  http://www.hani.co.kr/arti/sports/sports_gener...  \n",
      "13    http://www.hani.co.kr/arti/sports//1103188.html  \n",
      "14  http://www.hani.co.kr/arti/sports/soccer/11031...  \n",
      "15    http://www.hani.co.kr/arti/sports//1103131.html  \n",
      "16  http://www.hani.co.kr/arti/sports/sports_gener...  \n",
      "17  http://www.hani.co.kr/arti/sports/baseball/110...  \n",
      "18    http://www.hani.co.kr/arti/sports//1103093.html  \n",
      "19  http://www.hani.co.kr/arti/sports/sports_gener...  \n",
      "20    http://www.hani.co.kr/arti/sports//1103079.html  \n",
      "21  http://www.hani.co.kr/arti/sports/soccer/11030...  \n",
      "22  http://www.hani.co.kr/arti/sports/baseball/110...  \n",
      "23  http://www.hani.co.kr/arti/sports/baseball/110...  \n",
      "24  http://www.hani.co.kr/arti/sports/sports_gener...  \n",
      "25    http://www.hani.co.kr/arti/sports//1102999.html  \n",
      "26  http://www.hani.co.kr/arti/sports/soccer/11029...  \n",
      "27  http://www.hani.co.kr/arti/sports/soccer/11029...  \n",
      "28  http://www.hani.co.kr/arti/sports/sports_gener...  \n",
      "29  http://www.hani.co.kr/arti/sports/soccer/11028...  \n"
     ]
    }
   ],
   "source": [
    "rows = []\n",
    "for node in items:\n",
    "    s_title = node.find('title').text\n",
    "    s_link = node.find('link').text\n",
    "    print(s_title, s_link)\n",
    "    rows.append({\"title\":s_title, \"link\":s_link})\n",
    "df = pd.DataFrame(rows, columns=[\"title\", \"link\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e4ff590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function read_json in module pandas.io.json._json:\n",
      "\n",
      "read_json(path_or_buf: 'FilePath | ReadBuffer[str] | ReadBuffer[bytes]', *, orient: 'str | None' = None, typ: \"Literal['frame', 'series']\" = 'frame', dtype: 'DtypeArg | None' = None, convert_axes=None, convert_dates: 'bool | list[str]' = True, keep_default_dates: 'bool' = True, numpy: 'bool' = False, precise_float: 'bool' = False, date_unit: 'str | None' = None, encoding: 'str | None' = None, encoding_errors: 'str | None' = 'strict', lines: 'bool' = False, chunksize: 'int | None' = None, compression: 'CompressionOptions' = 'infer', nrows: 'int | None' = None, storage_options: 'StorageOptions' = None) -> 'DataFrame | Series | JsonReader'\n",
      "    Convert a JSON string to pandas object.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    path_or_buf : a valid JSON str, path object or file-like object\n",
      "        Any valid string path is acceptable. The string could be a URL. Valid\n",
      "        URL schemes include http, ftp, s3, and file. For file URLs, a host is\n",
      "        expected. A local file could be:\n",
      "        ``file://localhost/path/to/table.json``.\n",
      "    \n",
      "        If you want to pass in a path object, pandas accepts any\n",
      "        ``os.PathLike``.\n",
      "    \n",
      "        By file-like object, we refer to objects with a ``read()`` method,\n",
      "        such as a file handle (e.g. via builtin ``open`` function)\n",
      "        or ``StringIO``.\n",
      "    orient : str\n",
      "        Indication of expected JSON string format.\n",
      "        Compatible JSON strings can be produced by ``to_json()`` with a\n",
      "        corresponding orient value.\n",
      "        The set of possible orients is:\n",
      "    \n",
      "        - ``'split'`` : dict like\n",
      "          ``{index -> [index], columns -> [columns], data -> [values]}``\n",
      "        - ``'records'`` : list like\n",
      "          ``[{column -> value}, ... , {column -> value}]``\n",
      "        - ``'index'`` : dict like ``{index -> {column -> value}}``\n",
      "        - ``'columns'`` : dict like ``{column -> {index -> value}}``\n",
      "        - ``'values'`` : just the values array\n",
      "    \n",
      "        The allowed and default values depend on the value\n",
      "        of the `typ` parameter.\n",
      "    \n",
      "        * when ``typ == 'series'``,\n",
      "    \n",
      "          - allowed orients are ``{'split','records','index'}``\n",
      "          - default is ``'index'``\n",
      "          - The Series index must be unique for orient ``'index'``.\n",
      "    \n",
      "        * when ``typ == 'frame'``,\n",
      "    \n",
      "          - allowed orients are ``{'split','records','index',\n",
      "            'columns','values', 'table'}``\n",
      "          - default is ``'columns'``\n",
      "          - The DataFrame index must be unique for orients ``'index'`` and\n",
      "            ``'columns'``.\n",
      "          - The DataFrame columns must be unique for orients ``'index'``,\n",
      "            ``'columns'``, and ``'records'``.\n",
      "    \n",
      "    typ : {'frame', 'series'}, default 'frame'\n",
      "        The type of object to recover.\n",
      "    \n",
      "    dtype : bool or dict, default None\n",
      "        If True, infer dtypes; if a dict of column to dtype, then use those;\n",
      "        if False, then don't infer dtypes at all, applies only to the data.\n",
      "    \n",
      "        For all ``orient`` values except ``'table'``, default is True.\n",
      "    \n",
      "        .. versionchanged:: 0.25.0\n",
      "    \n",
      "           Not applicable for ``orient='table'``.\n",
      "    \n",
      "    convert_axes : bool, default None\n",
      "        Try to convert the axes to the proper dtypes.\n",
      "    \n",
      "        For all ``orient`` values except ``'table'``, default is True.\n",
      "    \n",
      "        .. versionchanged:: 0.25.0\n",
      "    \n",
      "           Not applicable for ``orient='table'``.\n",
      "    \n",
      "    convert_dates : bool or list of str, default True\n",
      "        If True then default datelike columns may be converted (depending on\n",
      "        keep_default_dates).\n",
      "        If False, no dates will be converted.\n",
      "        If a list of column names, then those columns will be converted and\n",
      "        default datelike columns may also be converted (depending on\n",
      "        keep_default_dates).\n",
      "    \n",
      "    keep_default_dates : bool, default True\n",
      "        If parsing dates (convert_dates is not False), then try to parse the\n",
      "        default datelike columns.\n",
      "        A column label is datelike if\n",
      "    \n",
      "        * it ends with ``'_at'``,\n",
      "    \n",
      "        * it ends with ``'_time'``,\n",
      "    \n",
      "        * it begins with ``'timestamp'``,\n",
      "    \n",
      "        * it is ``'modified'``, or\n",
      "    \n",
      "        * it is ``'date'``.\n",
      "    \n",
      "    numpy : bool, default False\n",
      "        Direct decoding to numpy arrays. Supports numeric data only, but\n",
      "        non-numeric column and index labels are supported. Note also that the\n",
      "        JSON ordering MUST be the same for each term if numpy=True.\n",
      "    \n",
      "        .. deprecated:: 1.0.0\n",
      "    \n",
      "    precise_float : bool, default False\n",
      "        Set to enable usage of higher precision (strtod) function when\n",
      "        decoding string to double values. Default (False) is to use fast but\n",
      "        less precise builtin functionality.\n",
      "    \n",
      "    date_unit : str, default None\n",
      "        The timestamp unit to detect if converting dates. The default behaviour\n",
      "        is to try and detect the correct precision, but if this is not desired\n",
      "        then pass one of 's', 'ms', 'us' or 'ns' to force parsing only seconds,\n",
      "        milliseconds, microseconds or nanoseconds respectively.\n",
      "    \n",
      "    encoding : str, default is 'utf-8'\n",
      "        The encoding to use to decode py3 bytes.\n",
      "    \n",
      "    encoding_errors : str, optional, default \"strict\"\n",
      "        How encoding errors are treated. `List of possible values\n",
      "        <https://docs.python.org/3/library/codecs.html#error-handlers>`_ .\n",
      "    \n",
      "        .. versionadded:: 1.3.0\n",
      "    \n",
      "    lines : bool, default False\n",
      "        Read the file as a json object per line.\n",
      "    \n",
      "    chunksize : int, optional\n",
      "        Return JsonReader object for iteration.\n",
      "        See the `line-delimited json docs\n",
      "        <https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#line-delimited-json>`_\n",
      "        for more information on ``chunksize``.\n",
      "        This can only be passed if `lines=True`.\n",
      "        If this is None, the file will be read into memory all at once.\n",
      "    \n",
      "        .. versionchanged:: 1.2\n",
      "    \n",
      "           ``JsonReader`` is a context manager.\n",
      "    \n",
      "    compression : str or dict, default 'infer'\n",
      "        For on-the-fly decompression of on-disk data. If 'infer' and 'path_or_buf' is\n",
      "        path-like, then detect compression from the following extensions: '.gz',\n",
      "        '.bz2', '.zip', '.xz', '.zst', '.tar', '.tar.gz', '.tar.xz' or '.tar.bz2'\n",
      "        (otherwise no compression).\n",
      "        If using 'zip' or 'tar', the ZIP file must contain only one data file to be read in.\n",
      "        Set to ``None`` for no decompression.\n",
      "        Can also be a dict with key ``'method'`` set\n",
      "        to one of {``'zip'``, ``'gzip'``, ``'bz2'``, ``'zstd'``, ``'tar'``} and other\n",
      "        key-value pairs are forwarded to\n",
      "        ``zipfile.ZipFile``, ``gzip.GzipFile``,\n",
      "        ``bz2.BZ2File``, ``zstandard.ZstdDecompressor`` or\n",
      "        ``tarfile.TarFile``, respectively.\n",
      "        As an example, the following could be passed for Zstandard decompression using a\n",
      "        custom compression dictionary:\n",
      "        ``compression={'method': 'zstd', 'dict_data': my_compression_dict}``.\n",
      "    \n",
      "            .. versionadded:: 1.5.0\n",
      "                Added support for `.tar` files.\n",
      "    \n",
      "        .. versionchanged:: 1.4.0 Zstandard support.\n",
      "    \n",
      "    nrows : int, optional\n",
      "        The number of lines from the line-delimited jsonfile that has to be read.\n",
      "        This can only be passed if `lines=True`.\n",
      "        If this is None, all the rows will be returned.\n",
      "    \n",
      "        .. versionadded:: 1.1\n",
      "    \n",
      "    storage_options : dict, optional\n",
      "        Extra options that make sense for a particular storage connection, e.g.\n",
      "        host, port, username, password, etc. For HTTP(S) URLs the key-value pairs\n",
      "        are forwarded to ``urllib.request.Request`` as header options. For other\n",
      "        URLs (e.g. starting with \"s3://\", and \"gcs://\") the key-value pairs are\n",
      "        forwarded to ``fsspec.open``. Please see ``fsspec`` and ``urllib`` for more\n",
      "        details, and for more examples on storage options refer `here\n",
      "        <https://pandas.pydata.org/docs/user_guide/io.html?\n",
      "        highlight=storage_options#reading-writing-remote-files>`_.\n",
      "    \n",
      "        .. versionadded:: 1.2.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    Series or DataFrame\n",
      "        The type returned depends on the value of `typ`.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    DataFrame.to_json : Convert a DataFrame to a JSON string.\n",
      "    Series.to_json : Convert a Series to a JSON string.\n",
      "    json_normalize : Normalize semi-structured JSON data into a flat table.\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Specific to ``orient='table'``, if a :class:`DataFrame` with a literal\n",
      "    :class:`Index` name of `index` gets written with :func:`to_json`, the\n",
      "    subsequent read operation will incorrectly set the :class:`Index` name to\n",
      "    ``None``. This is because `index` is also used by :func:`DataFrame.to_json`\n",
      "    to denote a missing :class:`Index` name, and the subsequent\n",
      "    :func:`read_json` operation cannot distinguish between the two. The same\n",
      "    limitation is encountered with a :class:`MultiIndex` and any names\n",
      "    beginning with ``'level_'``.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> df = pd.DataFrame([['a', 'b'], ['c', 'd']],\n",
      "    ...                   index=['row 1', 'row 2'],\n",
      "    ...                   columns=['col 1', 'col 2'])\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'split'`` formatted JSON:\n",
      "    \n",
      "    >>> df.to_json(orient='split')\n",
      "        '{\"columns\":[\"col 1\",\"col 2\"],\"index\":[\"row 1\",\"row 2\"],\"data\":[[\"a\",\"b\"],[\"c\",\"d\"]]}'\n",
      "    >>> pd.read_json(_, orient='split')\n",
      "          col 1 col 2\n",
      "    row 1     a     b\n",
      "    row 2     c     d\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'index'`` formatted JSON:\n",
      "    \n",
      "    >>> df.to_json(orient='index')\n",
      "    '{\"row 1\":{\"col 1\":\"a\",\"col 2\":\"b\"},\"row 2\":{\"col 1\":\"c\",\"col 2\":\"d\"}}'\n",
      "    \n",
      "    >>> pd.read_json(_, orient='index')\n",
      "          col 1 col 2\n",
      "    row 1     a     b\n",
      "    row 2     c     d\n",
      "    \n",
      "    Encoding/decoding a Dataframe using ``'records'`` formatted JSON.\n",
      "    Note that index labels are not preserved with this encoding.\n",
      "    \n",
      "    >>> df.to_json(orient='records')\n",
      "    '[{\"col 1\":\"a\",\"col 2\":\"b\"},{\"col 1\":\"c\",\"col 2\":\"d\"}]'\n",
      "    >>> pd.read_json(_, orient='records')\n",
      "      col 1 col 2\n",
      "    0     a     b\n",
      "    1     c     d\n",
      "    \n",
      "    Encoding with Table Schema\n",
      "    \n",
      "    >>> df.to_json(orient='table')\n",
      "        '{\"schema\":{\"fields\":[{\"name\":\"index\",\"type\":\"string\"},{\"name\":\"col 1\",\"type\":\"string\"},{\"name\":\"col 2\",\"type\":\"string\"}],\"primaryKey\":[\"index\"],\"pandas_version\":\"1.4.0\"},\"data\":[{\"index\":\"row 1\",\"col 1\":\"a\",\"col 2\":\"b\"},{\"index\":\"row 2\",\"col 1\":\"c\",\"col 2\":\"d\"}]}'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.read_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "db87463a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인포먼트\n",
      "엣지 오브 다크니스\n",
      "베이비 돌\n",
      "황야의 역마차\n",
      "전원 교향곡\n",
      "아버지의 깃발\n",
      "여덟번의감정\n",
      "레드\n",
      "영광의 탈출\n",
      "크로싱\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_json('http://swiftapi.rubypaper.co.kr:2029/hoppin/movies?version=1&page=1&count=10&genreId=&order=releasedateasc')\n",
    "#print(df)\n",
    "\n",
    "hoppin = df['hoppin']\n",
    "#print(hoppin)\n",
    "\n",
    "movies = hoppin['movies']\n",
    "#print(movies)\n",
    "\n",
    "movie = movies['movie']\n",
    "#print(movie)\n",
    "\n",
    "for temp in movie:\n",
    "    print(temp['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a854ad1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    integer            datetime  category\n",
      "0         5 2015-01-01 00:00:00         0\n",
      "1         5 2015-01-01 00:00:01         0\n",
      "2         9 2015-01-01 00:00:02         0\n",
      "3         6 2015-01-01 00:00:03         0\n",
      "4         6 2015-01-01 00:00:04         0\n",
      "..      ...                 ...       ...\n",
      "95        9 2015-01-01 00:01:35         0\n",
      "96        8 2015-01-01 00:01:36         0\n",
      "97        6 2015-01-01 00:01:37         0\n",
      "98        8 2015-01-01 00:01:38         0\n",
      "99        1 2015-01-01 00:01:39         0\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "#최신 라이브러리를 사용하면 이런 경우에도 데이터프레임으로 잘 변환이 되지만\n",
    "#컬럼에 객체가 존재하는 경우 제대로 파싱이 수행되지 않는 경우가 있음\n",
    "#컬럼 이름에 객체가 존재하는 경우는 orient 옵션에 columns를 설정하면 됩니다.\n",
    "df = pd.read_json('https://raw.githubusercontent.com/chrisalbon/simulated_datasets/master/data.json')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d171210",
   "metadata": {},
   "source": [
    "# 카카오 Open API 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "6f7d8e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남시약국\t서울 중구 남대문로3가 30-15\n",
      "평화약국\t서울 중구 남대문로4가 18-11\n",
      "수도약국\t서울 종로구 관훈동 37\n",
      "종로약국\t서울 종로구 종로4가 8\n",
      "서울중앙약국\t서울 용산구 동자동 43-205\n",
      "서울왕약국\t서울 중구 남창동 2-3\n",
      "왕솔약국\t서울 중구 회현동1가 202-1\n",
      "우정약국\t서울 종로구 종로4가 176-1\n",
      "삼원온누리약국\t서울 종로구 신문로1가 1\n",
      "새원약국\t서울 중구 명동1가 33\n",
      "종오약국\t서울 종로구 종로4가 7\n",
      "남대문약국\t서울 중구 남대문로3가 30-7\n",
      "종각호약국\t서울 종로구 종로2가 75-6\n",
      "푸른온누리약국\t서울 종로구 평동 180\n",
      "서대문권약국\t서울 종로구 평동 169\n"
     ]
    }
   ],
   "source": [
    "#c9c84cac73fdf3486202627ad13c5a6a\n",
    "\n",
    "import requests\n",
    "import json\n",
    "\n",
    "url = 'https://dapi.kakao.com/v2/local/search/category.json?category_group_code=PM9&rect=126.95,37.55,127.0,37.60'\n",
    "\n",
    "#전송할 헤더 만들기\n",
    "headers = {'Authorization' : 'KakaoAK c9c84cac73fdf3486202627ad13c5a6a'}\n",
    "\n",
    "data = requests.post(url, headers=headers)\n",
    "result = json.loads(data.text)\n",
    "\n",
    "for data in result['documents']:\n",
    "    print(data['place_name'], end='\\t')\n",
    "    print(data['address_name'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
